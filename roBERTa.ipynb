{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb2d2718",
   "metadata": {},
   "source": [
    "# RoBERTa\n",
    "Use RoBERTa Model with pretrained RoBERTa tokenizer from huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5d71c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Import Packages and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4df7fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import tqdm.auto as tqdm\n",
    "import transformers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a27740a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "DIR_PATH = os.getcwd()\n",
    "TRAIN_DATA_PATH = os.path.join(DIR_PATH, DATA_PATH, \"train.csv\")\n",
    "TEST_DATA_PATH = os.path.join(DIR_PATH, DATA_PATH, \"test.csv\")\n",
    "\n",
    "VALIDATION_RATIO = 0.05\n",
    "SEED = 1234\n",
    "\n",
    "REMOVE_DUPLICATE = False\n",
    "TRANSFORMER_NAME = \"roberta-base\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-7\n",
    "EPOCHS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15323f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a5ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418b216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.tqdm.pandas()# enable progress_apply and progress_map for pandas\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba8534",
   "metadata": {},
   "source": [
    "## Data Preprocessed and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cdd5eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the single worst film i've ever seen in a thea...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was actually around 13 years old camping nea...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A small town is attacked by a horde of bloodth...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think the problem with this show not getting...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow, this movie was horrible. As a Bills fan I...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  the single worst film i've ever seen in a thea...  negative\n",
       "1  I was actually around 13 years old camping nea...  positive\n",
       "2  A small town is attacked by a horde of bloodth...  negative\n",
       "3  I think the problem with this show not getting...  positive\n",
       "4  Wow, this movie was horrible. As a Bills fan I...  negative"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test = pd.read_csv(TEST_DATA_PATH)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f571c358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>An expedition party made up of constantly bick...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, I'll be honest: It is not exactly a Shol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This is not a boring movie, the audience might...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My boyfriend and I decided to go see this movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It's a shame this movie is rated PG 13--it is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review\n",
       "0   0  An expedition party made up of constantly bick...\n",
       "1   1  Well, I'll be honest: It is not exactly a Shol...\n",
       "2   2  This is not a boring movie, the audience might...\n",
       "3   3  My boyfriend and I decided to go see this movi...\n",
       "4   4  It's a shame this movie is rated PG 13--it is ..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9f255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicated Data\n",
    "if REMOVE_DUPLICATE:\n",
    "    print(train_data.duplicated(subset=[\"review\"]).sum())\n",
    "    train_data.drop_duplicates(subset=[\"review\"], inplace=True)\n",
    "    train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d9585ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "742cdf609459448ab95684aaff3abdc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the single worst film i've ever seen in a thea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was actually around 13 years old camping nea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A small town is attacked by a horde of bloodth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think the problem with this show not getting...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow, this movie was horrible. As a Bills fan I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  the single worst film i've ever seen in a thea...          0\n",
       "1  I was actually around 13 years old camping nea...          1\n",
       "2  A small town is attacked by a horde of bloodth...          0\n",
       "3  I think the problem with this show not getting...          1\n",
       "4  Wow, this movie was horrible. As a Bills fan I...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"sentiment\"] = train_data[\"sentiment\"].progress_map(\n",
    "    lambda x:1 if x == \"positive\" else 0\n",
    "    )\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b4174ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tockenizer\n",
    "tokenizer = transformers.RobertaTokenizer.from_pretrained(TRANSFORMER_NAME)\n",
    "\n",
    "def tokenize_function(examples, tokenizer):\n",
    "    return tokenizer(examples, truncation=True)[\"input_ids\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95d264f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c724b255b24186905f272cf6c2f6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06e409de0cf422db58116acd678d368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data[\"input_ids\"] = train_data[\"review\"].progress_map(lambda x :tokenize_function(x, tokenizer=tokenizer))\n",
    "test[\"input_ids\"] = test[\"review\"].progress_map(lambda x :tokenize_function(x, tokenizer=tokenizer))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c091442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the single worst film i've ever seen in a thea...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 627, 881, 2373, 822, 939, 348, 655, 450, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was actually around 13 years old camping nea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 100, 21, 888, 198, 508, 107, 793, 16724, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A small town is attacked by a horde of bloodth...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 250, 650, 1139, 16, 4487, 30, 10, 44666, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think the problem with this show not getting...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 100, 206, 5, 936, 19, 42, 311, 45, 562, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wow, this movie was horrible. As a Bills fan I...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 23692, 6, 42, 1569, 21, 11385, 4, 287, 10,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  the single worst film i've ever seen in a thea...          0   \n",
       "1  I was actually around 13 years old camping nea...          1   \n",
       "2  A small town is attacked by a horde of bloodth...          0   \n",
       "3  I think the problem with this show not getting...          1   \n",
       "4  Wow, this movie was horrible. As a Bills fan I...          0   \n",
       "\n",
       "                                           input_ids  \n",
       "0  [0, 627, 881, 2373, 822, 939, 348, 655, 450, 1...  \n",
       "1  [0, 100, 21, 888, 198, 508, 107, 793, 16724, 5...  \n",
       "2  [0, 250, 650, 1139, 16, 4487, 30, 10, 44666, 9...  \n",
       "3  [0, 100, 206, 5, 936, 19, 42, 311, 45, 562, 5,...  \n",
       "4  [0, 23692, 6, 42, 1569, 21, 11385, 4, 287, 10,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65186280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>An expedition party made up of constantly bick...</td>\n",
       "      <td>[0, 4688, 25512, 537, 156, 62, 9, 5861, 741, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Well, I'll be honest: It is not exactly a Shol...</td>\n",
       "      <td>[0, 8346, 6, 38, 581, 28, 5322, 35, 85, 16, 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This is not a boring movie, the audience might...</td>\n",
       "      <td>[0, 713, 16, 45, 10, 15305, 1569, 6, 5, 2437, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My boyfriend and I decided to go see this movi...</td>\n",
       "      <td>[0, 2387, 6578, 8, 38, 1276, 7, 213, 192, 42, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>It's a shame this movie is rated PG 13--it is ...</td>\n",
       "      <td>[0, 243, 18, 10, 9208, 42, 1569, 16, 5211, 144...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review  \\\n",
       "0   0  An expedition party made up of constantly bick...   \n",
       "1   1  Well, I'll be honest: It is not exactly a Shol...   \n",
       "2   2  This is not a boring movie, the audience might...   \n",
       "3   3  My boyfriend and I decided to go see this movi...   \n",
       "4   4  It's a shame this movie is rated PG 13--it is ...   \n",
       "\n",
       "                                           input_ids  \n",
       "0  [0, 4688, 25512, 537, 156, 62, 9, 5861, 741, 1...  \n",
       "1  [0, 8346, 6, 38, 581, 28, 5322, 35, 85, 16, 45...  \n",
       "2  [0, 713, 16, 45, 10, 15305, 1569, 6, 5, 2437, ...  \n",
       "3  [0, 2387, 6578, 8, 38, 1276, 7, 213, 192, 42, ...  \n",
       "4  [0, 243, 18, 10, 9208, 42, 1569, 16, 5211, 144...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bf79a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token # Padding token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a63d8213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id # Padding token id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1543cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this index as padding value\n",
    "pad_index = tokenizer.pad_token_id "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e887d274",
   "metadata": {},
   "source": [
    "## Split trainning  set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c53bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = train_test_split(train_data, \n",
    "                                          test_size=VALIDATION_RATIO,\n",
    "                                          random_state=SEED)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "valid_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9496cc0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114000, 6000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size, valid_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c114af4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What an empty and lack lustre rendition of the...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 2264, 41, 5802, 8, 1762, 30864, 241, 25202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad plot (though good for a B-movie), good fas...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 26954, 6197, 36, 18401, 205, 13, 10, 163, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is one of the worst movies ever made. Tri...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 713, 16, 65, 9, 5, 2373, 4133, 655, 156, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This series was a cut above the rest of the TV...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 713, 651, 21, 10, 847, 1065, 5, 1079, 9, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You can only describe this with one word and t...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1185, 64, 129, 6190, 42, 19, 65, 2136, 8, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment  \\\n",
       "0  What an empty and lack lustre rendition of the...          0   \n",
       "1  Bad plot (though good for a B-movie), good fas...          0   \n",
       "2  This is one of the worst movies ever made. Tri...          0   \n",
       "3  This series was a cut above the rest of the TV...          1   \n",
       "4  You can only describe this with one word and t...          0   \n",
       "\n",
       "                                           input_ids  \n",
       "0  [0, 2264, 41, 5802, 8, 1762, 30864, 241, 25202...  \n",
       "1  [0, 26954, 6197, 36, 18401, 205, 13, 10, 163, ...  \n",
       "2  [0, 713, 16, 65, 9, 5, 2373, 4133, 655, 156, 4...  \n",
       "3  [0, 713, 651, 21, 10, 847, 1065, 5, 1079, 9, 5...  \n",
       "4  [0, 1185, 64, 129, 6190, 42, 19, 65, 2136, 8, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a48a76",
   "metadata": {},
   "source": [
    "## Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831a4ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset\n",
    "    Args:\n",
    "        data (pd.DataFrame): DataFrame containing 'input_ids' and 'sentiment' columns.\n",
    "    \"\"\"\n",
    "    def __init__(self, data:pd.DataFrame):\n",
    "        super().__init__()\n",
    "        self.ids = data[\"input_ids\"].to_list()\n",
    "        self.labels = data[\"sentiment\"].to_list()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        ids_tensor = torch.tensor(self.ids[ind], dtype=torch.int64)\n",
    "\n",
    "        labels_tensor = torch.tensor(self.labels[ind], dtype=torch.int64)\n",
    "        return {\"ids\" : ids_tensor, \"label\" : labels_tensor}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b625f7c",
   "metadata": {},
   "source": [
    "### Make custon collate function for padding\n",
    "Since the review length is different, we need to pad the input_ids to the same length in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f342b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = [i[\"ids\"] for i in batch]\n",
    "        batch_ids = nn.utils.rnn.pad_sequence(\n",
    "            batch_ids, padding_value=pad_index, batch_first=True\n",
    "        )\n",
    "        batch_label = [i[\"label\"] for i in batch]\n",
    "        batch_label = torch.stack(batch_label)\n",
    "        batch = {\"ids\": batch_ids, \"label\": batch_label}\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce83b1a",
   "metadata": {},
   "source": [
    "### Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e69687cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(dataset, batch_size, pad_index, shuffle=True):\n",
    "    \"\"\"Get DataLoader with custom collate_fn for padding.\"\"\"\n",
    "    collate_fn = get_collate_fn(pad_index)\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc338c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset(train_data)\n",
    "valid_dataset = dataset(valid_data)\n",
    "\n",
    "train_loader = get_data_loader(train_dataset, BATCH_SIZE, \n",
    "                               pad_index, shuffle=True)\n",
    "valid_loader = get_data_loader(valid_dataset, BATCH_SIZE, \n",
    "                               pad_index, shuffle=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a312b",
   "metadata": {},
   "source": [
    "## Model \n",
    "Build and Fine-tune the pre-trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "408e1782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, transformer_name, num_classes, freeze):\n",
    "        super().__init__()\n",
    "        self.transformer = transformers.RobertaModel.from_pretrained(transformer_name)\n",
    "        self.classifier = nn.Linear(self.transformer.config.hidden_size,\n",
    "                                    num_classes)\n",
    "        if freeze:\n",
    "            for param in self.transformer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        outputs = self.transformer(input_ids=input_ids).last_hidden_state\n",
    "        cls_output = outputs[:, 0, :]  # [CLS] token output\n",
    "        logits = self.classifier(torch.tanh(cls_output))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "afccdec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dim = len(train_data[\"sentiment\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90f31139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(TRANSFORMER_NAME, output_dim, freeze=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2811bb",
   "metadata": {},
   "source": [
    "## Trainning and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c98e27",
   "metadata": {},
   "source": [
    "### Trainning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c59e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6eabdc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a7b107",
   "metadata": {},
   "source": [
    "## Trainning, Evaluating and Computing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3090ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(prediction, label):\n",
    "    batch_size, _ = prediction.shape\n",
    "    predicted_classes = prediction.argmax(dim=-1)\n",
    "    correct_predictions = predicted_classes.eq(label).sum()\n",
    "    accuracy = correct_predictions / batch_size\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aeea618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"evaluating...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            label = batch[\"label\"].to(device)\n",
    "            prediction = model(ids)\n",
    "            loss = criterion(prediction, label)\n",
    "            accuracy = get_accuracy(prediction, label)\n",
    "            epoch_losses.append(loss.item())\n",
    "            epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8525c9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    epoch_losses = []\n",
    "    epoch_accs = []\n",
    "    for batch in tqdm.tqdm(data_loader, desc=\"training...\"):\n",
    "        ids = batch[\"ids\"].to(device)\n",
    "        label = batch[\"label\"].to(device)\n",
    "        prediction = model(ids)\n",
    "        loss = criterion(prediction, label)\n",
    "        accuracy = get_accuracy(prediction, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_losses.append(loss.item())\n",
    "        epoch_accs.append(accuracy.item())\n",
    "    return np.mean(epoch_losses), np.mean(epoch_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9022723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4ab65e9889432898e91b39187aaca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training...:   0%|          | 0/1188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c9586b27034555a16cb29e6c25397a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "evaluating...:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "train_loss: 0.693, train_acc: 0.514\n",
      "valid_loss: 0.691, valid_acc: 0.541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f84aab39ebd453c85f42c86b8bc88cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training...:   0%|          | 0/1188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m metrics \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      4\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_accs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      5\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m      6\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid_accs\u001b[39m\u001b[38;5;124m\"\u001b[39m: []}\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m----> 9\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     valid_loss, valid_acc \u001b[38;5;241m=\u001b[39m evaluate(valid_loader, model, criterion, DEVICE)\n\u001b[1;32m     13\u001b[0m     metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[31], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(data_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 14\u001b[0m     epoch_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     epoch_accs\u001b[38;5;241m.\u001b[39mappend(accuracy\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(epoch_losses), np\u001b[38;5;241m.\u001b[39mmean(epoch_accs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "metrics = {\"train_losses\": [],\n",
    "           \"train_accs\": [],\n",
    "           \"valid_losses\": [],\n",
    "           \"valid_accs\": []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(\n",
    "        train_loader, model, criterion, optimizer, DEVICE\n",
    "    )\n",
    "    valid_loss, valid_acc = evaluate(valid_loader, model, criterion, DEVICE)\n",
    "    metrics[\"train_losses\"].append(train_loss)\n",
    "    metrics[\"train_accs\"].append(train_acc)\n",
    "    metrics[\"valid_losses\"].append(valid_loss)\n",
    "    metrics[\"valid_accs\"].append(valid_acc)\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), \"transformer.pt\")\n",
    "    print(f\"epoch: {epoch}\")\n",
    "    print(f\"train_loss: {train_loss:.3f}, train_acc: {train_acc:.3f}\")\n",
    "    print(f\"valid_loss: {valid_loss:.3f}, valid_acc: {valid_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c71697",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd05cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(metrics[\"train_losses\"], label=\"train loss\")\n",
    "ax.plot(metrics[\"valid_losses\"], label=\"valid loss\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_xticks(range(EPOCHS))\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e59bac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(metrics[\"train_accs\"], label=\"train accuracy\")\n",
    "ax.plot(metrics[\"valid_accs\"], label=\"valid accuracy\")\n",
    "ax.set_xlabel(\"epoch\")\n",
    "ax.set_ylabel(\"loss\")\n",
    "ax.set_xticks(range(EPOCHS))\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9619b3b",
   "metadata": {},
   "source": [
    "## Generate the test answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9bf904",
   "metadata": {},
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, data:pd.DataFrame):\n",
    "        super().__init__()\n",
    "        self.ids = data[\"input_ids\"].to_list()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, ind):\n",
    "        ids_tensor = torch.tensor(self.ids[ind], dtype=torch.int64)\n",
    "        return ids_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222c72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collate_fn(pad_index):\n",
    "    def collate_fn(batch):\n",
    "        batch_ids = [i for i in batch]\n",
    "        batch_ids = nn.utils.rnn.pad_sequence(\n",
    "            batch_ids, padding_value=pad_index, batch_first=True\n",
    "        )\n",
    "        batch = {\"ids\": batch_ids}\n",
    "        return batch\n",
    "\n",
    "    return collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm.tqdm(data_loader, desc=\"predicting...\"):\n",
    "            ids = batch[\"ids\"].to(device)\n",
    "            prediction = model(ids)\n",
    "            preds.append(prediction)\n",
    "    return torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best model\n",
    "model.load_state_dict(torch.load(\"transformer.pt\"))\n",
    "model = model.to(DEVICE)\n",
    "test_dataset = testDataset(test)\n",
    "test_loader = get_data_loader(test_dataset, BATCH_SIZE, \n",
    "                               pad_index, shuffle=False)\n",
    "predictions = predict(test_loader, model, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = predictions.argmax(dim=-1)\n",
    "answer = pd.DataFrame({\"id\" : test[\"id\"],\n",
    "                       \"sentiment\": [\"positive\" if i == 1 else \"negative\" for i in prediction_classes.cpu().numpy()]})\n",
    "answer.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec290ea",
   "metadata": {},
   "source": [
    "### Clean GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d34b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentimen-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
